{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames[:1]:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-05-12T00:05:30.465565Z","iopub.execute_input":"2023-05-12T00:05:30.466407Z","iopub.status.idle":"2023-05-12T00:05:31.334527Z","shell.execute_reply.started":"2023-05-12T00:05:30.466370Z","shell.execute_reply":"2023-05-12T00:05:31.333576Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"/kaggle/input/renewdata/sample_submission.csv\n/kaggle/input/renewdata/test/641.png\n/kaggle/input/renewdata/train/가구수정/11.png\n/kaggle/input/renewdata/train/터짐/94.png\n/kaggle/input/renewdata/train/들뜸/48.png\n/kaggle/input/renewdata/train/피스/48.png\n/kaggle/input/renewdata/train/창틀,문틀수정/11.png\n/kaggle/input/renewdata/train/녹오염/11.png\n/kaggle/input/renewdata/train/석고수정/48.png\n/kaggle/input/renewdata/train/훼손/1231.png\n/kaggle/input/renewdata/train/꼬임/173.png\n/kaggle/input/renewdata/train/울음/11.png\n/kaggle/input/renewdata/train/걸레받이수정/173.png\n/kaggle/input/renewdata/train/틈새과다/4.png\n/kaggle/input/renewdata/train/오염/173.png\n/kaggle/input/renewdata/train/곰팡이/94.png\n/kaggle/input/renewdata/train/이음부불량/11.png\n/kaggle/input/renewdata/train/면불량/94.png\n/kaggle/input/renewdata/train/반점/1.png\n/kaggle/input/renewdata/train/오타공/94.png\n/kaggle/input/renewdata/train/몰딩수정/94.png\n/kaggle/input/csvfile/ISSUE_HW_DAY_2021-07_2021-07_2021.csv\n","output_type":"stream"}]},{"cell_type":"markdown","source":"augmented images 생성해둔 것","metadata":{}},{"cell_type":"code","source":"import random\nimport pandas as pd\nimport numpy as np\nimport os\nimport re\nimport glob\nimport cv2\n\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport torch.nn.functional as F\nfrom torch.utils.data import Dataset, DataLoader, WeightedRandomSampler\n\nimport albumentations as A\nfrom albumentations.pytorch.transforms import ToTensorV2\nimport torchvision.models as models\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn import preprocessing\nfrom sklearn.metrics import f1_score\nfrom sklearn.metrics import classification_report\nfrom tqdm.auto import tqdm\n\nimport warnings\nwarnings.filterwarnings(action='ignore') ","metadata":{"execution":{"iopub.status.busy":"2023-05-12T00:10:11.500716Z","iopub.execute_input":"2023-05-12T00:10:11.501095Z","iopub.status.idle":"2023-05-12T00:10:15.553948Z","shell.execute_reply.started":"2023-05-12T00:10:11.501066Z","shell.execute_reply":"2023-05-12T00:10:15.552949Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n","output_type":"stream"}]},{"cell_type":"code","source":"device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n\n\nCFG = {\n    'IMG_SIZE':384,\n    'EPOCHS':50,\n    'LEARNING_RATE':2e-4,\n    'BATCH_SIZE':32,\n    'SEED':42\n}\n\n\ndef seed_everything(seed):\n    random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.backends.cudnn.deterministic = True\n    torch.backends.cudnn.benchmark = True\n\nseed_everything(CFG['SEED']) # Seed...","metadata":{"execution":{"iopub.status.busy":"2023-05-12T00:10:32.487850Z","iopub.execute_input":"2023-05-12T00:10:32.488468Z","iopub.status.idle":"2023-05-12T00:10:32.526207Z","shell.execute_reply.started":"2023-05-12T00:10:32.488431Z","shell.execute_reply":"2023-05-12T00:10:32.525164Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":"augmented images 코드\n","metadata":{}},{"cell_type":"code","source":"all_img_list = glob.glob('/kaggle/input/renewdata/train/*/*')\n\ndf = pd.DataFrame(columns=['img_path', 'label'])\ndf['img_path'] = all_img_list\ndf['label'] = df['img_path'].apply(lambda x : str(x).split('/')[-2])\ndf['label'].value_counts()","metadata":{"execution":{"iopub.status.busy":"2023-05-12T00:11:19.418330Z","iopub.execute_input":"2023-05-12T00:11:19.418718Z","iopub.status.idle":"2023-05-12T00:11:19.470979Z","shell.execute_reply.started":"2023-05-12T00:11:19.418679Z","shell.execute_reply":"2023-05-12T00:11:19.469965Z"},"trusted":true},"execution_count":5,"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"훼손         1405\n오염          595\n걸레받이수정      307\n꼬임          210\n터짐          162\n곰팡이         145\n오타공         142\n몰딩수정        130\n면불량          99\n석고수정         57\n들뜸           54\n피스           51\n창틀,문틀수정      27\n울음           22\n이음부불량        17\n녹오염          14\n가구수정         12\n틈새과다          5\n반점            3\nName: label, dtype: int64"},"metadata":{}}]},{"cell_type":"code","source":"le = preprocessing.LabelEncoder()\ndf['label'] = le.fit_transform(df['label'])","metadata":{"execution":{"iopub.status.busy":"2023-05-12T00:12:00.597603Z","iopub.execute_input":"2023-05-12T00:12:00.597957Z","iopub.status.idle":"2023-05-12T00:12:00.605667Z","shell.execute_reply.started":"2023-05-12T00:12:00.597929Z","shell.execute_reply":"2023-05-12T00:12:00.604696Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"class CustomDataset(Dataset):\n    def __init__(self, img_path_list, label_list, transforms=None):\n        self.img_path_list = img_path_list\n        self.label_list = label_list\n        self.transforms = transforms\n        \n    def __getitem__(self, index):\n        img_path = self.img_path_list[index]\n        \n        image = cv2.imread(img_path)\n        \n        if self.transforms is not None:\n            image = self.transforms(image=image)['image']\n        \n        if self.label_list is not None:\n            label = self.label_list[index]\n            return image, label\n        else:\n            return image\n        \n    def __len__(self):\n        return len(self.img_path_list)","metadata":{"execution":{"iopub.status.busy":"2023-05-12T00:13:07.710552Z","iopub.execute_input":"2023-05-12T00:13:07.711432Z","iopub.status.idle":"2023-05-12T00:13:07.719095Z","shell.execute_reply.started":"2023-05-12T00:13:07.711388Z","shell.execute_reply":"2023-05-12T00:13:07.717951Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"train_transform = A.Compose([\n                            A.Resize(CFG['IMG_SIZE'],CFG['IMG_SIZE']),\n                            A.HorizontalFlip(),\n                            A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225), max_pixel_value=255.0, always_apply=False, p=1.0),\n                            ToTensorV2()\n                            ])\n\ntest_transform = A.Compose([\n                            A.Resize(CFG['IMG_SIZE'],CFG['IMG_SIZE']),\n                            A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225), max_pixel_value=255.0, always_apply=False, p=1.0), # ImageNet에서 쓰는 픽셀 분포\n                            ToTensorV2()\n                            ])","metadata":{"execution":{"iopub.status.busy":"2023-05-12T00:15:05.478581Z","iopub.execute_input":"2023-05-12T00:15:05.478949Z","iopub.status.idle":"2023-05-12T00:15:05.488561Z","shell.execute_reply.started":"2023-05-12T00:15:05.478919Z","shell.execute_reply":"2023-05-12T00:15:05.486722Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"class BaseModel(nn.Module):\n    def __init__(self, num_classes=len(le.classes_)):\n        super(BaseModel, self).__init__()\n        self.backbone = models.efficientnet_b1(pretrained=True)\n        self.classifier = nn.Linear(1000, num_classes)\n        \n    def forward(self, x):\n        x = self.backbone(x)\n        x = self.classifier(x)\n        return x","metadata":{"execution":{"iopub.status.busy":"2023-05-12T00:16:58.004745Z","iopub.execute_input":"2023-05-12T00:16:58.005376Z","iopub.status.idle":"2023-05-12T00:16:58.019284Z","shell.execute_reply.started":"2023-05-12T00:16:58.005331Z","shell.execute_reply":"2023-05-12T00:16:58.018293Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"def train(model, optimizer, train_loader, val_loader, scheduler, device):\n    model.to(device)\n    criterion = nn.CrossEntropyLoss().to(device)\n    \n    best_score = 0\n    best_model = None\n    num_patience = 7\n    cur_patience = 0\n    for epoch in range(1, CFG['EPOCHS']+1):\n        model.train()\n        train_loss = []\n        for imgs, labels in tqdm(iter(train_loader)):\n            imgs = imgs.float().to(device)\n            labels = labels.to(device)\n            \n            optimizer.zero_grad()\n            \n            output = model(imgs)\n            loss = criterion(output, labels)\n            \n            loss.backward()\n            optimizer.step()\n            \n            train_loss.append(loss.item())\n                    \n        _val_loss, _val_score = validation(model, criterion, val_loader, device)\n        _train_loss = np.mean(train_loss)\n        print(f'Epoch [{epoch}], Train Loss : [{_train_loss:.5f}] Val Loss : [{_val_loss:.5f}] Val Weighted F1 Score : [{_val_score:.5f}]')\n       \n        if scheduler is not None:\n            scheduler.step(_val_score)\n            \n        if best_score < _val_score:\n            best_score = _val_score\n            best_model = model\n            cur_patience = 0\n        else :\n            cur_patience+=1\n            print(cur_patience)\n            if cur_patience>=num_patience:\n                break\n    return best_model\n\ndef validation(model, criterion, val_loader, device):\n    model.eval()\n    val_loss = []\n    \n\n    with torch.no_grad():\n        for imgs, labels in tqdm(iter(val_loader)):\n            imgs = imgs.float().to(device)\n            labels = labels.to(device)\n            \n            pred = model(imgs)\n            \n            loss = criterion(pred, labels)\n            \n            preds += pred.argmax(1).detach().cpu().numpy().tolist()\n            true_labels += labels.detach().cpu().numpy().tolist()\n            \n            val_loss.append(loss.item())\n        \n        _val_loss = np.mean(val_loss)\n        _val_score = f1_score(true_labels, preds, average='weighted')\n    \n    return _val_loss, _val_score","metadata":{"execution":{"iopub.status.busy":"2023-05-12T00:18:54.670432Z","iopub.execute_input":"2023-05-12T00:18:54.671277Z","iopub.status.idle":"2023-05-12T00:18:54.686770Z","shell.execute_reply.started":"2023-05-12T00:18:54.671241Z","shell.execute_reply":"2023-05-12T00:18:54.685834Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"def inference(model, test_loader, device):\n    model.eval()\n    preds = []\n    with torch.no_grad():\n        for imgs in tqdm(iter(test_loader)):\n            imgs = imgs.float().to(device)\n            \n            pred = model(imgs)\n            \n            preds += pred.argmax(1).detach().cpu().numpy().tolist()\n    \n    preds = le.inverse_transform(preds)  ## 앙상블 할땐 확률값 반환\n    return preds","metadata":{"execution":{"iopub.status.busy":"2023-05-12T00:23:47.392774Z","iopub.execute_input":"2023-05-12T00:23:47.393792Z","iopub.status.idle":"2023-05-12T00:23:47.400573Z","shell.execute_reply.started":"2023-05-12T00:23:47.393755Z","shell.execute_reply":"2023-05-12T00:23:47.399614Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import StratifiedKFold\nskf = StratifiedKFold(n_splits = 3, shuffle=True, random_state = 45) ## n_splits >= 5\n\ntest = pd.read_csv('/kaggle/input/renewdata/test.csv')\ntest[\"img_path\"] = \"/kaggle/input/renewdata\" + test[\"img_path\"].str[1:]\n\nresult = []\nfor train_index, valid_index in skf.split(df, df[\"label\"]):\n    x_train = df.iloc[train_index]\n    x_valid = df.iloc[valid_index]\n    train_dataset = CustomDataset(x_train['img_path'].values, x_train['label'].values, train_transform)\n    train_loader = DataLoader(train_dataset, batch_size = CFG['BATCH_SIZE'], shuffle=True, num_workers=0)\n\n    val_dataset = CustomDataset(x_valid['img_path'].values, x_valid['label'].values, test_transform)\n    val_loader = DataLoader(val_dataset, batch_size=CFG['BATCH_SIZE'], shuffle=False, num_workers=0)\n    \n    \n    model = BaseModel()\n    model.eval()\n    optimizer = torch.optim.Adam(params = model.parameters(), lr = CFG[\"LEARNING_RATE\"])\n    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', factor=0.2, patience=3, threshold_mode='abs', min_lr=1e-8, verbose=True)\n\n    infer_model = train(model, optimizer, train_loader, val_loader, scheduler, device)\n    \n\n    test_dataset = CustomDataset(test['img_path'].values, None, test_transform)\n    test_loader = DataLoader(test_dataset, batch_size=CFG['BATCH_SIZE'], shuffle=False, num_workers=0)\n    \n    preds = inference(infer_model, test_loader, device)\n    result.append(preds)   ## hard/soft voting\n    ## TTA 추가 예정\n","metadata":{"execution":{"iopub.status.busy":"2023-05-12T00:26:13.907137Z","iopub.execute_input":"2023-05-12T00:26:13.907545Z","iopub.status.idle":"2023-05-12T00:26:32.521292Z","shell.execute_reply.started":"2023-05-12T00:26:13.907515Z","shell.execute_reply":"2023-05-12T00:26:32.519865Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":16,"outputs":[{"name":"stderr","text":"Downloading: \"https://download.pytorch.org/models/efficientnet_b1_rwightman-533bc792.pth\" to /root/.cache/torch/hub/checkpoints/efficientnet_b1_rwightman-533bc792.pth\n100%|██████████| 30.1M/30.1M [00:00<00:00, 114MB/s] \n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/72 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"116fdb9488034468bc633319fab8d836"}},"metadata":{}},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[16], line 23\u001b[0m\n\u001b[1;32m     20\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39moptim\u001b[38;5;241m.\u001b[39mAdam(params \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mparameters(), lr \u001b[38;5;241m=\u001b[39m CFG[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLEARNING_RATE\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m     21\u001b[0m scheduler \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39moptim\u001b[38;5;241m.\u001b[39mlr_scheduler\u001b[38;5;241m.\u001b[39mReduceLROnPlateau(optimizer, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmax\u001b[39m\u001b[38;5;124m'\u001b[39m, factor\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m, patience\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m, threshold_mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mabs\u001b[39m\u001b[38;5;124m'\u001b[39m, min_lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1e-8\u001b[39m, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m---> 23\u001b[0m infer_model \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscheduler\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     26\u001b[0m test_dataset \u001b[38;5;241m=\u001b[39m CustomDataset(test[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mimg_path\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mvalues, \u001b[38;5;28;01mNone\u001b[39;00m, test_transform)\n\u001b[1;32m     27\u001b[0m test_loader \u001b[38;5;241m=\u001b[39m DataLoader(test_dataset, batch_size\u001b[38;5;241m=\u001b[39mCFG[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBATCH_SIZE\u001b[39m\u001b[38;5;124m'\u001b[39m], shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, num_workers\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n","Cell \u001b[0;32mIn[13], line 21\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(model, optimizer, train_loader, val_loader, scheduler, device)\u001b[0m\n\u001b[1;32m     18\u001b[0m output \u001b[38;5;241m=\u001b[39m model(imgs)\n\u001b[1;32m     19\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(output, labels)\n\u001b[0;32m---> 21\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     22\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     24\u001b[0m train_loss\u001b[38;5;241m.\u001b[39mappend(loss\u001b[38;5;241m.\u001b[39mitem())\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/_tensor.py:487\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    477\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    478\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    479\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    480\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    485\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    486\u001b[0m     )\n\u001b[0;32m--> 487\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    488\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    489\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/autograd/__init__.py:200\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    195\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    197\u001b[0m \u001b[38;5;66;03m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[1;32m    198\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    199\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 200\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    201\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    202\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}]},{"cell_type":"code","source":"submit = pd.read_csv('/kaggle/input/renewdata/sample_submission.csv')\nsubmit['label'] = preds\nsubmit.to_csv('baseline_submit.csv', index=False)\nsubmit","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}}]}